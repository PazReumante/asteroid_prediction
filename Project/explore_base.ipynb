{"cells":[{"cell_type":"markdown","metadata":{},"source":["#### **ANÁLISIS DE LA DISTANCIA MÍNIMA DE INTERSECCIÓN ORBITAL ASTEROIDAL**"]},{"cell_type":"markdown","metadata":{},"source":["#### **EDA**"]},{"cell_type":"markdown","metadata":{},"source":["1. **Carga y concatenación de datos**"]},{"cell_type":"code","execution_count":232,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\loren\\AppData\\Local\\Temp\\ipykernel_17328\\1232100427.py:5: DtypeWarning: Columns (3,4) have mixed types. Specify dtype option on import or set low_memory=False.\n","  part3 = pd.read_csv('../Data/dataset_part3.csv')\n","C:\\Users\\loren\\AppData\\Local\\Temp\\ipykernel_17328\\1232100427.py:7: DtypeWarning: Columns (4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n","  part5 = pd.read_csv('../Data/dataset_part5.csv')\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>spkid</th>\n","      <th>full_name</th>\n","      <th>pdes</th>\n","      <th>name</th>\n","      <th>prefix</th>\n","      <th>neo</th>\n","      <th>pha</th>\n","      <th>H</th>\n","      <th>diameter</th>\n","      <th>...</th>\n","      <th>sigma_i</th>\n","      <th>sigma_om</th>\n","      <th>sigma_w</th>\n","      <th>sigma_ma</th>\n","      <th>sigma_ad</th>\n","      <th>sigma_n</th>\n","      <th>sigma_tp</th>\n","      <th>sigma_per</th>\n","      <th>class</th>\n","      <th>rms</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>a0000001</td>\n","      <td>2000001</td>\n","      <td>1 Ceres</td>\n","      <td>1</td>\n","      <td>Ceres</td>\n","      <td>NaN</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>3.4</td>\n","      <td>939.4</td>\n","      <td>...</td>\n","      <td>4.608900e-09</td>\n","      <td>6.168800e-08</td>\n","      <td>6.624800e-08</td>\n","      <td>7.820700e-09</td>\n","      <td>1.111300e-11</td>\n","      <td>1.196500e-12</td>\n","      <td>3.782900e-08</td>\n","      <td>9.415900e-09</td>\n","      <td>MBA</td>\n","      <td>0.43301</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows × 45 columns</p>\n","</div>"],"text/plain":["         id    spkid     full_name pdes   name prefix neo pha    H  diameter  \\\n","0  a0000001  2000001       1 Ceres    1  Ceres    NaN   N   N  3.4     939.4   \n","\n","   ...       sigma_i      sigma_om       sigma_w      sigma_ma      sigma_ad  \\\n","0  ...  4.608900e-09  6.168800e-08  6.624800e-08  7.820700e-09  1.111300e-11   \n","\n","        sigma_n      sigma_tp     sigma_per  class      rms  \n","0  1.196500e-12  3.782900e-08  9.415900e-09    MBA  0.43301  \n","\n","[1 rows x 45 columns]"]},"execution_count":232,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","part1 = pd.read_csv('../Data/dataset_part1.csv')\n","part2 = pd.read_csv('../Data/dataset_part2.csv')\n","part3 = pd.read_csv('../Data/dataset_part3.csv')\n","part4 = pd.read_csv('../Data/dataset_part4.csv')\n","part5 = pd.read_csv('../Data/dataset_part5.csv')\n","\n","total_data = pd.concat([part1, part2, part3, part4, part5], ignore_index=True)\n","total_data.head(1)"]},{"cell_type":"code","execution_count":233,"metadata":{},"outputs":[{"data":{"text/plain":["Index(['id', 'spkid', 'full_name', 'pdes', 'name', 'prefix', 'neo', 'pha', 'H',\n","       'diameter', 'albedo', 'diameter_sigma', 'orbit_id', 'epoch',\n","       'epoch_mjd', 'epoch_cal', 'equinox', 'e', 'a', 'q', 'i', 'om', 'w',\n","       'ma', 'ad', 'n', 'tp', 'tp_cal', 'per', 'per_y', 'moid', 'moid_ld',\n","       'sigma_e', 'sigma_a', 'sigma_q', 'sigma_i', 'sigma_om', 'sigma_w',\n","       'sigma_ma', 'sigma_ad', 'sigma_n', 'sigma_tp', 'sigma_per', 'class',\n","       'rms'],\n","      dtype='object')"]},"execution_count":233,"metadata":{},"output_type":"execute_result"}],"source":["total_data.columns"]},{"cell_type":"markdown","metadata":{},"source":["Como la cantidad de datos es muy grande (mas de 900000 datos) cogemos una muestra aleatoria de 150000\n"]},{"cell_type":"code","execution_count":226,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>spkid</th>\n","      <th>full_name</th>\n","      <th>pdes</th>\n","      <th>name</th>\n","      <th>prefix</th>\n","      <th>neo</th>\n","      <th>pha</th>\n","      <th>H</th>\n","      <th>diameter</th>\n","      <th>...</th>\n","      <th>sigma_i</th>\n","      <th>sigma_om</th>\n","      <th>sigma_w</th>\n","      <th>sigma_ma</th>\n","      <th>sigma_ad</th>\n","      <th>sigma_n</th>\n","      <th>sigma_tp</th>\n","      <th>sigma_per</th>\n","      <th>class</th>\n","      <th>rms</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>323650</th>\n","      <td>a0323651</td>\n","      <td>2323651</td>\n","      <td>323651 (2005 BR20)</td>\n","      <td>323651</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>18.2</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>0.000005</td>\n","      <td>0.000134</td>\n","      <td>0.000138</td>\n","      <td>0.000034</td>\n","      <td>1.785700e-08</td>\n","      <td>2.987900e-09</td>\n","      <td>0.000114</td>\n","      <td>0.000013</td>\n","      <td>MBA</td>\n","      <td>0.73452</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows × 45 columns</p>\n","</div>"],"text/plain":["              id    spkid           full_name    pdes name prefix neo pha  \\\n","323650  a0323651  2323651  323651 (2005 BR20)  323651  NaN    NaN   N   N   \n","\n","           H  diameter  ...   sigma_i  sigma_om   sigma_w  sigma_ma  \\\n","323650  18.2       NaN  ...  0.000005  0.000134  0.000138  0.000034   \n","\n","            sigma_ad       sigma_n  sigma_tp  sigma_per  class      rms  \n","323650  1.785700e-08  2.987900e-09  0.000114   0.000013    MBA  0.73452  \n","\n","[1 rows x 45 columns]"]},"execution_count":226,"metadata":{},"output_type":"execute_result"}],"source":["'''sample_total_data = total_data.sample(n=150000, random_state=42)\n","sample_total_data.head(1)'''"]},{"cell_type":"code","execution_count":234,"metadata":{},"outputs":[{"data":{"text/plain":["958524"]},"execution_count":234,"metadata":{},"output_type":"execute_result"}],"source":["import sqlite3\n","\n","conn = sqlite3.connect(\"asteroids_database.db\")\n","\n","#Creamos una tabla para almacenar los datos, se insertan los datos del DataFrame en la tabla SQL\n","total_data.to_sql(\"asteroids_table\", conn, if_exists = \"replace\", index = False)"]},{"cell_type":"code","execution_count":235,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame leído de la base de datos SQL:\n","         id    spkid            full_name        pdes  name prefix neo pha  \\\n","0  bK13Y07Y  3849676           (2013 YY7)    2013 YY7  None   None   N   N   \n","1  bK16T60A  3855849          (2016 TA60)   2016 TA60  None   None   N   N   \n","2  bK16P76Z  3757690          (2016 PZ76)   2016 PZ76  None   None   N   N   \n","3  bK06WA2J  3364218         (2006 WJ102)  2006 WJ102  None   None   N   N   \n","4  bK04VB0L  3804214         (2004 VL110)  2004 VL110  None   None   N   N   \n","\n","      H  diameter  ...   sigma_i  sigma_om   sigma_w  sigma_ma      sigma_ad  \\\n","0  18.1       NaN  ...  0.000028  0.000346  0.002062  0.002805  4.974500e-06   \n","1  17.2       NaN  ...  0.000011  0.000178  0.000237  0.000164  1.308700e-07   \n","2  16.8       NaN  ...  0.000013  0.000041  0.000063  0.000077  1.931200e-07   \n","3  18.3       NaN  ...  0.000025  0.000374  0.000389  0.000127  4.450100e-08   \n","4  18.0       NaN  ...  0.000016  0.000067  0.000102  0.000088  6.632500e-08   \n","\n","        sigma_n  sigma_tp  sigma_per  class      rms  \n","0  5.384700e-07  0.010587   0.003778    MBA  0.52591  \n","1  1.372800e-08  0.000783   0.000112    MBA  0.57880  \n","2  1.780800e-08  0.000385   0.000146    MBA  0.59362  \n","3  7.033900e-09  0.000464   0.000034    MBA  0.76743  \n","4  9.887500e-09  0.000348   0.000051    MBA  0.60170  \n","\n","[5 rows x 45 columns]\n"]}],"source":["query = '''\n","    SELECT *\n","    FROM asteroids_table\n","    ORDER BY RANDOM()\n","    LIMIT 150000\n","'''\n","\n","sample_total_data = pd.read_sql_query(query, conn)\n","\n","print(\"DataFrame leído de la base de datos SQL:\")\n","\n","print(sample_total_data.head())\n","\n","#Cerrar la conexión\n","\n","conn.close()"]},{"cell_type":"code","execution_count":236,"metadata":{},"outputs":[],"source":["# Guardado de la muestra\n","sample_total_data.to_csv('sampled_dataset.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["Creación de una nueva tabla para almacenar los datos, se insertarán los datos del DataFrame en la tabla SQL."]},{"cell_type":"code","execution_count":228,"metadata":{},"outputs":[{"data":{"text/plain":["150000"]},"execution_count":228,"metadata":{},"output_type":"execute_result"}],"source":["'''import sqlite3\n","\n","conn = sqlite3.connect(\"asteroids_database.db\")\n","\n","sample_total_data.to_sql(\"asteroids_table\", conn, if_exists = \"replace\", index = False)'''"]},{"cell_type":"code","execution_count":229,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame leído de la base de datos SQL:\n","         id    spkid           full_name       pdes  name prefix neo pha  \\\n","0  a0323651  2323651  323651 (2005 BR20)     323651  None   None   N   N   \n","1  bK04C47Q  3242421         (2004 CQ47)  2004 CQ47  None   None   N   N   \n","2  a0395984  2395984  395984 (2013 BV32)     395984  None   None   N   N   \n","3  a0235863  2235863  235863 (2005 AY53)     235863  None   None   N   N   \n","4  bK09B35Q  3445579         (2009 BQ35)  2009 BQ35  None   None   N   N   \n","\n","      H  diameter  ...   sigma_i  sigma_om   sigma_w  sigma_ma      sigma_ad  \\\n","0  18.2       NaN  ...  0.000005  0.000134  0.000138  0.000034  1.785700e-08   \n","1  17.7       NaN  ...  0.000006  0.000062  0.000075  0.000047  5.644400e-08   \n","2  17.4       NaN  ...  0.000009  0.000113  0.000119  0.000041  5.827700e-08   \n","3  15.1     6.539  ...  0.000006  0.000034  0.000041  0.000029  5.184000e-08   \n","4  17.3       NaN  ...  0.000009  0.000081  0.000114  0.000069  5.354400e-08   \n","\n","        sigma_n  sigma_tp  sigma_per  class      rms  \n","0  2.987900e-09  0.000114   0.000013    MBA  0.73452  \n","1  6.310600e-09  0.000198   0.000040    MBA  0.59010  \n","2  6.375200e-09  0.000191   0.000047    MBA  0.47752  \n","3  3.813600e-09  0.000174   0.000043    MBA  0.56332  \n","4  5.324700e-09  0.000334   0.000041    MBA  0.61287  \n","\n","[5 rows x 45 columns]\n"]}],"source":["'''sample_total_data = pd.read_sql_query('SELECT * FROM asteroids_table', conn)\n","\n","print(\"DataFrame leído de la base de datos SQL:\")\n","\n","print(sample_total_data.head())\n","\n","#Cerrar la conexión\n","\n","conn.close()'''"]},{"cell_type":"code","execution_count":237,"metadata":{},"outputs":[{"data":{"text/plain":["(150000, 45)"]},"execution_count":237,"metadata":{},"output_type":"execute_result"}],"source":["# Tamaño del dataset\n","sample_total_data.shape"]},{"cell_type":"code","execution_count":231,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 150000 entries, 0 to 149999\n","Data columns (total 45 columns):\n"," #   Column          Non-Null Count   Dtype  \n","---  ------          --------------   -----  \n"," 0   id              150000 non-null  object \n"," 1   spkid           150000 non-null  int64  \n"," 2   full_name       150000 non-null  object \n"," 3   pdes            150000 non-null  object \n"," 4   name            3466 non-null    object \n"," 5   prefix          6 non-null       object \n"," 6   neo             149999 non-null  object \n"," 7   pha             146825 non-null  object \n"," 8   H               148974 non-null  float64\n"," 9   diameter        21312 non-null   float64\n"," 10  albedo          21147 non-null   float64\n"," 11  diameter_sigma  21283 non-null   float64\n"," 12  orbit_id        150000 non-null  object \n"," 13  epoch           150000 non-null  float64\n"," 14  epoch_mjd       150000 non-null  int64  \n"," 15  epoch_cal       150000 non-null  float64\n"," 16  equinox         150000 non-null  object \n"," 17  e               150000 non-null  float64\n"," 18  a               150000 non-null  float64\n"," 19  q               150000 non-null  float64\n"," 20  i               150000 non-null  float64\n"," 21  om              150000 non-null  float64\n"," 22  w               150000 non-null  float64\n"," 23  ma              150000 non-null  float64\n"," 24  ad              149999 non-null  float64\n"," 25  n               150000 non-null  float64\n"," 26  tp              150000 non-null  float64\n"," 27  tp_cal          150000 non-null  float64\n"," 28  per             149999 non-null  float64\n"," 29  per_y           150000 non-null  float64\n"," 30  moid            146825 non-null  float64\n"," 31  moid_ld         149981 non-null  float64\n"," 32  sigma_e         146825 non-null  float64\n"," 33  sigma_a         146825 non-null  float64\n"," 34  sigma_q         146825 non-null  float64\n"," 35  sigma_i         146825 non-null  float64\n"," 36  sigma_om        146825 non-null  float64\n"," 37  sigma_w         146825 non-null  float64\n"," 38  sigma_ma        146825 non-null  float64\n"," 39  sigma_ad        146824 non-null  float64\n"," 40  sigma_n         146825 non-null  float64\n"," 41  sigma_tp        146825 non-null  float64\n"," 42  sigma_per       146824 non-null  float64\n"," 43  class           150000 non-null  object \n"," 44  rms             150000 non-null  float64\n","dtypes: float64(33), int64(2), object(10)\n","memory usage: 51.5+ MB\n"]}],"source":["# Información del dataset\n","sample_total_data.info()"]},{"cell_type":"markdown","metadata":{},"source":["2. **Exploración y limpieza de datos**"]},{"cell_type":"markdown","metadata":{},"source":["Eliminación de duplicados -> no hay duplicados"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if sample_total_data_sql.duplicated().sum():\n","    sample_total_data = sample_total_data.drop_duplicates()\n","print(sample_total_data_sql.shape)\n","sample_total_data_sql.head(1)"]},{"cell_type":"markdown","metadata":{},"source":["Contabilización de columnas numéricas y categóricas"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Identificar columnas numéricas\n","numeric_columns = sample_total_data.select_dtypes(include=['float64','int64']).columns.tolist()\n","\n","# Identificar columnas categóricas\n","categorical_columns = sample_total_data.select_dtypes(include=['object', 'category']).columns.tolist()\n","\n","# Imprimir los resultados\n","print(f'Número de columnas numéricas: {len(numeric_columns)}')\n","print('Columnas numéricas:', numeric_columns)\n","\n","print(f'Número de columnas categóricas: {len(categorical_columns)}')\n","print('Columnas categóricas:', categorical_columns)"]},{"cell_type":"markdown","metadata":{},"source":["Eliminamos las columnas de `id` que nos propocionan info y los sigmas, que son incertidumbres del resto de variables."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sample_total_data.drop([\"id\", \"spkid\", \"full_name\",\"pdes\",\"name\",\"prefix\",\"orbit_id\",\"rms\",\"sigma_e\",'sigma_e', 'sigma_a', 'sigma_q', 'sigma_i', 'sigma_om', 'sigma_w', 'sigma_ma', 'sigma_ad', 'sigma_n', 'sigma_tp', 'sigma_per'], axis = 1, inplace = True)\n","sample_total_data.head(1)"]},{"cell_type":"markdown","metadata":{},"source":["3. Análisis de variables univariante"]},{"cell_type":"markdown","metadata":{},"source":["No se graficará \"host_name\" -> existen demasiados nombres como para crear histograma"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Análisis variables categóricas 'neo', 'pha', 'equinox', 'class'\n","import matplotlib.pyplot as plt \n","import seaborn as sns\n","fig, axis = plt.subplots(2, 2, figsize = (15, 10))\n","\n","# Histograma múltiple\n","#\"host_name\" -> existen demasiados nombres como para crear histograma\n","\n","sns.histplot(ax = axis[0][0], data = sample_total_data, x = \"neo\")\n","sns.histplot(ax = axis[0][1], data = sample_total_data, x = \"pha\")\n","sns.histplot(ax = axis[1][0], data = sample_total_data, x = \"equinox\")\n","sns.histplot(ax = axis[1][1], data = sample_total_data, x = \"class\")\n","\n","# Ajustar el layout\n","plt.tight_layout()\n","\n","# Mostrar el plot\n","plt.show()\n","\n","print(\"Conclusiones:\")\n","print(\"\\nneo: la mayoría de objetos no son cercanos a la tierra\")\n","print(\"\\npha: la mayoría de objetos no son potencialmente peligroso\")\n","print(\"\\nequinox:sólo existe una categoría, podemos eliminarla\")\n","print(\"\\nclass: la mayoría de asterioides son de clase MBA (Main Belt Asteroid). Son asteroides procedentes del cinturón principal que se encuentra entre Marte y Júpiter\")"]},{"cell_type":"markdown","metadata":{},"source":["Eliminación de información irrelevante de variables categóricas, conclusión sacada de representación histograma"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sample_total_data.drop([\"equinox\"], axis = 1, inplace = True)\n","sample_total_data.head(1)"]},{"cell_type":"markdown","metadata":{},"source":["Análisis univariante variables numéricas ``H``, ``diameter``, ``diameter_sigma``, ``albedo``, ``epoch``, ``epoch_mjd``, ``epoch_cal``, ``e``, ``a``, ``q``, ``i``, ``om``, ``w``, ``ma``, ``ad``, ``n``, ``tp``, ``tp_cal``, ``per``, ``per_y``, ``moid``, ``moid_ld``\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","fig, axis = plt.subplots(4, 4, figsize = (30, 15), gridspec_kw={'height_ratios': [6, 1, 6, 1]})\n","\n","\n","sns.histplot(ax = axis[0, 0], data = sample_total_data, x = \"H\")\n","sns.boxplot(ax = axis[1, 0], data = sample_total_data, x = \"H\")\n","\n","sns.histplot(ax = axis[0, 1], data = sample_total_data, x = \"diameter\") \n","sns.boxplot(ax = axis[1, 1], data = sample_total_data, x = \"diameter\")\n","\n","sns.histplot(ax = axis[0, 2], data = sample_total_data, x = \"diameter_sigma\")\n","sns.boxplot(ax = axis[1, 2], data = sample_total_data, x = \"diameter_sigma\")\n","\n","sns.histplot(ax = axis[0, 3], data = sample_total_data, x = \"albedo\") \n","sns.boxplot(ax = axis[1, 3], data = sample_total_data, x = \"albedo\")\n","\n","sns.histplot(ax = axis[2, 0], data = sample_total_data, x = \"epoch\")\n","sns.boxplot(ax = axis[3, 0], data = sample_total_data, x = \"epoch\")\n","\n","sns.histplot(ax = axis[2, 1], data = sample_total_data, x = \"epoch_mjd\") \n","sns.boxplot(ax = axis[3, 1], data = sample_total_data, x = \"epoch_mjd\")\n","\n","sns.histplot(ax = axis[2, 2], data = sample_total_data, x = \"epoch_cal\")\n","sns.boxplot(ax = axis[3, 2], data = sample_total_data, x = \"epoch_cal\")\n","\n","sns.histplot(ax = axis[2, 3], data = sample_total_data, x = \"e\")\n","sns.boxplot(ax = axis[3, 3], data = sample_total_data, x = \"e\")\n","\n","plt.tight_layout()\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# 'a', 'q', 'i', 'om', 'w', 'ma', 'ad', 'n'\n","\n","fig, axis = plt.subplots(4, 4, figsize = (30, 15), gridspec_kw={'height_ratios': [6, 1, 6, 1]})\n","\n","\n","sns.histplot(ax = axis[0, 0], data = sample_total_data, x = \"a\")\n","sns.boxplot(ax = axis[1, 0], data = sample_total_data, x = \"a\")\n","\n","sns.histplot(ax = axis[0, 1], data = sample_total_data, x = \"q\") \n","sns.boxplot(ax = axis[1, 1], data = sample_total_data, x = \"q\")\n","\n","sns.histplot(ax = axis[0, 2], data = sample_total_data, x = \"i\")\n","sns.boxplot(ax = axis[1, 2], data = sample_total_data, x = \"i\")\n","\n","sns.histplot(ax = axis[0, 3], data = sample_total_data, x = \"om\") \n","sns.boxplot(ax = axis[1, 3], data = sample_total_data, x = \"om\")\n","\n","sns.histplot(ax = axis[2, 0], data = sample_total_data, x = \"w\")\n","sns.boxplot(ax = axis[3, 0], data = sample_total_data, x = \"w\")\n","\n","sns.histplot(ax = axis[2, 1], data = sample_total_data, x = \"ma\") \n","sns.boxplot(ax = axis[3, 1], data = sample_total_data, x = \"ma\")\n","\n","sns.histplot(ax = axis[2, 2], data = sample_total_data, x = \"ad\")\n","sns.boxplot(ax = axis[3, 2], data = sample_total_data, x = \"ad\")\n","\n","sns.histplot(ax = axis[2, 3], data = sample_total_data, x = \"n\")\n","sns.boxplot(ax = axis[3, 3], data = sample_total_data, x = \"n\")\n","\n","plt.tight_layout()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["``tp``, ``tp_cal``, ``per``, ``per_y``, ``moid``, ``moid_ld``"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, axis = plt.subplots(4, 3, figsize = (30, 15), gridspec_kw={'height_ratios': [6, 1, 6, 1]})\n","\n","\n","sns.histplot(ax = axis[0, 0], data = sample_total_data, x = \"tp\")\n","sns.boxplot(ax = axis[1, 0], data = sample_total_data, x = \"tp\")\n","\n","sns.histplot(ax = axis[0, 1], data = sample_total_data, x = \"tp_cal\") \n","sns.boxplot(ax = axis[1, 1], data = sample_total_data, x = \"tp_cal\")\n","\n","sns.histplot(ax = axis[0, 2], data = sample_total_data, x = \"per\")\n","sns.boxplot(ax = axis[1, 2], data = sample_total_data, x = \"per\")\n","\n","sns.histplot(ax = axis[2, 0], data = sample_total_data, x = \"per_y\") \n","sns.boxplot(ax = axis[3, 0], data = sample_total_data, x = \"per_y\")\n","\n","sns.histplot(ax = axis[2, 1], data = sample_total_data, x = \"moid\")\n","sns.boxplot(ax = axis[3, 1], data = sample_total_data, x = \"moid\")\n","\n","sns.histplot(ax = axis[2, 2], data = sample_total_data, x = \"moid_ld\") \n","sns.boxplot(ax = axis[3, 2], data = sample_total_data, x = \"moid_ld\")\n","\n","plt.tight_layout()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Eliminación de epoch y epoch_cal al ser redundantes con ``epoch_mjd`` (la que está modificada para ser mas manejable)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sample_total_data.drop(['epoch','epoch_cal'], axis = 1, inplace = True)\n","sample_total_data.head(1)"]},{"cell_type":"markdown","metadata":{},"source":["4. Análisis de variables multivariante"]},{"cell_type":"markdown","metadata":{},"source":["Analisis de variables categorica - categorica --> El mayor porcentaje de asteroides está lejos del planeta tierra"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Crear una nueva columna combinando las variables deseadas\n","sample_total_data['combined_hue'] = (sample_total_data['pha'].astype(str) + '_' +\n","                                     \n","                                     sample_total_data['class'].astype(str))\n","\n","# Crear el gráfico\n","fig, axis = plt.subplots(figsize=(10, 5))\n","\n","sns.countplot(data=sample_total_data, x=\"neo\", hue=\"combined_hue\", ax=axis, legend=False)\n","\n","# Definir la leyenda personalizada\n","legend_labels = {'N_NEO_orbit_id_equinox_class': 'N: Lejano a la Tierra',\n","                 'Y_NEO_orbit_id_equinox_class': 'Y: Cercano a la Tierra'}\n","\n","# Crear la leyenda manualmente\n","handles = []\n","for key, label in legend_labels.items():\n","    handles.append(axis.bar(0, 0, color='gray', label=label))  # Crear una barra dummy para cada etiqueta\n","\n","# Mostrar la leyenda fuera del gráfico\n","axis.legend(handles=handles, labels=legend_labels.values(), loc='upper right', title='Cercanía a la Tierra')\n","\n","# Mostrar el gráfico\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Análisis de correlaciones variables categóricas"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Factoriazción de variables categóricas\n","sample_total_data[\"neo_n\"] = pd.factorize(sample_total_data[\"neo\"])[0]\n","sample_total_data[\"pha_n\"] = pd.factorize(sample_total_data[\"pha\"])[0]\n","sample_total_data[\"class_n\"] = pd.factorize(sample_total_data[\"class\"])[0]\n","\n","fig, axis = plt.subplots(figsize = (10, 6))\n","\n","sns.heatmap(sample_total_data[[\"neo_n\", \"pha_n\", \"class_n\"]].corr(), annot = True, fmt = \".2f\")\n","\n","plt.tight_layout()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Análisis numérico-numérico -> scatter plots and heatmaps"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","ig, axis = plt.subplots(6, 3, figsize=(15, 30))\n","\n","\n","sns.regplot(data=sample_total_data, x=\"H\", y=\"moid\", ax=axis[0, 0]) \n","sns.heatmap(sample_total_data[[\"moid\", \"H\"]].corr(), annot=True, fmt=\".2f\", ax=axis[1, 0], cbar=False)\n","\n","sns.regplot(data=sample_total_data, x=\"diameter\", y=\"moid\", ax=axis[0, 1]) \n","sns.heatmap(sample_total_data[[\"moid\", \"diameter\"]].corr(), annot=True, fmt=\".2f\", ax=axis[1, 1], cbar=False)\n","\n","sns.regplot(data=sample_total_data, x=\"albedo\", y=\"moid\", ax=axis[0, 2]) \n","sns.heatmap(sample_total_data[[\"moid\", \"albedo\"]].corr(), annot=True, fmt=\".2f\", ax=axis[1, 2], cbar=False)\n","\n","sns.regplot(data=sample_total_data, x=\"diameter_sigma\", y=\"moid\", ax=axis[2, 0]) \n","sns.heatmap(sample_total_data[[\"moid\", \"diameter_sigma\"]].corr(), annot=True, fmt=\".2f\", ax=axis[3, 0], cbar=False)\n","\n","sns.regplot(data=sample_total_data, x=\"a\", y=\"moid\", ax=axis[2, 1]) \n","sns.heatmap(sample_total_data[[\"moid\", \"a\"]].corr(), annot=True, fmt=\".2f\", ax=axis[3, 1], cbar=False)\n","\n","sns.regplot(data=sample_total_data, x=\"q\", y=\"moid\", ax=axis[2, 2]) \n","sns.heatmap(sample_total_data[[\"moid\", \"q\"]].corr(), annot=True, fmt=\".2f\", ax=axis[3, 2], cbar=False)\n","\n","sns.regplot(data=sample_total_data, x=\"ad\", y=\"moid\", ax=axis[4, 0]) \n","sns.heatmap(sample_total_data[[\"moid\", \"ad\"]].corr(), annot=True, fmt=\".2f\", ax=axis[5, 0], cbar=False)\n","\n","sns.regplot(data=sample_total_data, x=\"n\", y=\"moid\", ax=axis[4, 1]) \n","sns.heatmap(sample_total_data[[\"moid\", \"n\"]].corr(), annot=True, fmt=\".2f\", ax=axis[5, 1], cbar=False)\n","\n","sns.regplot(data=sample_total_data, x=\"tp_cal\", y=\"moid\", ax=axis[4, 2]) \n","sns.heatmap(sample_total_data[[\"moid\", \"tp_cal\"]].corr(), annot=True, fmt=\".2f\", ax=axis[5, 2], cbar=False)\n","\n","# Adjust layout\n","plt.tight_layout()\n","\n","# Show the plot\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["Eliminación de información irrelevante de variables numéricas -> ``per`` y ``moid_Id`` por ser información irrelevante, las demás por no tener correlación.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sample_total_data.drop([\"per\",\"moid_ld\", \"epoch_mjd\",\"e\", \"i\", \"om\", \"w\", \"ma\", \"tp\"], axis = 1, inplace = True)\n","sample_total_data.head(1)"]},{"cell_type":"markdown","metadata":{},"source":["Análisis numérico-categórico completo."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","fig, axis = plt.subplots(figsize = (15, 15))\n","\n","sns.heatmap(sample_total_data[['H', 'diameter', 'albedo', 'diameter_sigma', 'a', 'q', 'ad', 'n', 'tp_cal', 'per_y', 'moid', 'neo_n', 'pha_n', 'class_n']].corr(), annot = True, fmt = \".2f\")\n","\n","plt.tight_layout()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Eliminación de variables numéricas-categóricas por no tener correlación con variable objetivo ``moid``"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sample_total_data.drop([\"neo_n\",\"pha_n\"], axis = 1, inplace = True)\n","sample_total_data.head(1)"]},{"cell_type":"markdown","metadata":{},"source":["Contabilización de columnas numéricas y categóricas después del análisis multivariante."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Identificar columnas numéricas\n","numeric_columns = sample_total_data.select_dtypes(include=['float64','int64']).columns.tolist()\n","\n","# Identificar columnas categóricas\n","categorical_columns = sample_total_data.select_dtypes(include=['object', 'category']).columns.tolist()\n","\n","# Imprimir los resultados\n","print(f'Número de columnas numéricas: {len(numeric_columns)}')\n","print('Columnas numéricas:', numeric_columns)\n","\n","print(f'Número de columnas categóricas: {len(categorical_columns)}')\n","print('Columnas categóricas:', categorical_columns)"]},{"cell_type":"markdown","metadata":{},"source":["5. Ingeniería de características"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Análisis de outliers\n","sample_total_data.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Analisis de outline `H`\n","\n","H_stats = sample_total_data[\"H\"].describe()\n","H_stats"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# IQR para `H`\n","h_iqr = H_stats[\"75%\"] - H_stats[\"25%\"]\n","\n","upper_limit = H_stats[\"75%\"] + 1.5 * h_iqr\n","limite_inferior = H_stats[\"25%\"] - 1.5 * H_stats\n","\n","print(f\"Los límites superior e inferior para encontrar valores atípicos son {round (upper_limit, 2)} y {round(limite_inferior, 2)}, con un rango intercuartílico de {round(h_iqr, 2)}\")"]},{"cell_type":"markdown","metadata":{},"source":["Los valores negativos significan que el objeto va en la dirección izquerda, al tratarse de direccionalidad no se hace relevante el ajuste de datos de esta variable."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Analisis de outline `diameter`\n","\n","diameter_stats = sample_total_data[\"diameter\"].describe()\n","diameter_stats"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# IQR para `diameter_sigma`\n","diameter_iqr = diameter_stats[\"75%\"] - diameter_stats[\"25%\"]\n","\n","upper_limit = diameter_stats[\"75%\"] + 1.5 * diameter_iqr\n","limite_inferior = diameter_stats[\"25%\"] - 1.5 * diameter_iqr\n","\n","print(f\"Los límites superior e inferior para encontrar valores atípicos son {round (upper_limit, 2)} y {round(limite_inferior, 2)}, con un rango intercuartílico de {round(diameter_iqr, 2)}\")"]},{"cell_type":"markdown","metadata":{},"source":["Los diametros no pueden ser negativos, sin embargo en cuanto a valores faltantes está variable tiene más del 80% por lo que no se considera su ajuste."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Analisis de outline `diameter_sigma`\n","\n","sigma_stats = sample_total_data[\"diameter_sigma\"].describe()\n","sigma_stats"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# IQR para `diameter_sigma`\n","sigma_iqr = sigma_stats[\"75%\"] - sigma_stats[\"25%\"]\n","\n","upper_limit = sigma_stats[\"75%\"] + 1.5 * sigma_iqr\n","limite_inferior = sigma_stats[\"25%\"] - 1.5 * sigma_iqr\n","\n","print(f\"Los límites superior e inferior para encontrar valores atípicos son {round (upper_limit, 2)} y {round(limite_inferior, 2)}, con un rango intercuartílico de {round(sigma_iqr, 2)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Analisis de outline `albedo`\n","\n","albedo_stats = sample_total_data[\"albedo\"].describe()\n","albedo_stats"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# IQR para `albedo`\n","albedo_iqr = albedo_stats[\"75%\"] - albedo_stats[\"25%\"]\n","\n","upper_limit = albedo_stats[\"75%\"] + 1.5 * albedo_iqr\n","limite_inferior = albedo_stats[\"25%\"] - 1.5 * albedo_iqr\n","\n","print(f\"Los límites superior e inferior para encontrar valores atípicos son {round (upper_limit, 2)} y {round(limite_inferior, 2)}, con un rango intercuartílico de {round(albedo_iqr, 2)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Variables a analizar 'tp_cal', 'per_y', 'moid'\n","fig, axis = plt.subplots(3, 1, figsize = (15, 10))\n","\n","sns.boxplot(ax = axis[0], data = sample_total_data, x = \"tp_cal\")\n","sns.boxplot(ax = axis[1], data = sample_total_data, x = \"per_y\")\n","sns.boxplot(ax = axis[2], data = sample_total_data, x = \"moid\")"]},{"cell_type":"markdown","metadata":{},"source":["- ``tp_call``: Tiempo de paso por el perihelio, ¿son posibles las fechasde los outliers?\n","- ``per_y``: ¿puede un asteroide tardar 20000 años en completar una órbita? -> sí. Por tanto, no eliminamos ningún outlier.\n","- ``moid´`` : Distancia mínima de intersección de la órbita (distancia más cercana a la órbita de la Tierra, en unidades astronómicas).\n","- Unidad astronómica 1UA = 149 597 870 700 m\n","- No podemos eliminar los outliers de la derecha ya que son factibles\n","- Estudio del outlier = 0 (siguiente caja de código)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["filtered_df = sample_total_data[sample_total_data['moid'] == 0]"]},{"cell_type":"markdown","metadata":{},"source":["Estudio del outlier = 0 de ``moid`` -> búsqueda de la fila que contiene ese valor -> No hay ningún valor = 0, son pequeños pero no llegan a 0. Por lo que pueden ser factibles -> no se elimina ningún outlier."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Variables específicas para el análisis\n","variables = ['a', 'q', 'ad', 'n']\n","\n","# Función para calcular outliers utilizando el rango intercuartílico (IQR)\n","def calculate_outliers(df, column):\n","    Q1 = df[column].quantile(0.25)\n","    Q3 = df[column].quantile(0.75)\n","    IQR = Q3 - Q1\n","    lower_bound = Q1 - 1.5 * IQR\n","    upper_bound = Q3 + 1.5 * IQR\n","    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n","    return outliers, lower_bound, upper_bound\n","\n","# Análisis descriptivo y gráficos de caja\n","for col in variables:\n","    print(f'\\nAnálisis descriptivo de la variable {col}:')\n","    print(sample_total_data[col].describe())\n","    \n","    # Calcular y mostrar outliers\n","    outliers, lower_bound, upper_bound = calculate_outliers(sample_total_data, col)\n","    print(f'Número de outliers en {col}: {len(outliers)}')\n","    print(f'Valores límite inferior y superior para {col}: {lower_bound}, {upper_bound}')\n","    print(f'Outliers en {col}:\\n', outliers[[col]])\n","    \n","    # Crear el gráfico de caja\n","    plt.figure(figsize=(8, 5))\n","    sns.boxplot(x=sample_total_data[col])\n","    plt.title(f'Diagrama de Caja para {col}')\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Análisis de valores faltantes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sample_total_data.isnull().sum().sort_values(ascending=False)"]},{"cell_type":"markdown","metadata":{},"source":["- Existe una pérdida de información importante en ``albedo``, ``diámeter`` y ``diameter_sigma``\n","- Como sus correlaciones son bajas (0.28, 0.26 y 0.24 respectivamente) eliminamos estas columnas y trabajamos con las demás que tienen correlaciones mas altas."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Valores faltantes en porcentaje\n","sample_total_data.isnull().sum().sort_values(ascending=False) / len(sample_total_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sample_total_data.drop([\"diameter\",\"diameter_sigma\",\"albedo\"], axis = 1, inplace = True)\n","sample_total_data.head(1)"]},{"cell_type":"markdown","metadata":{},"source":["Contabilización de columnas numéricas y categóricas después de eliminar columnas por valores faltantes."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Identificar columnas numéricas\n","numeric_columns = sample_total_data.select_dtypes(include=['float64','int64']).columns.tolist()\n","\n","# Identificar columnas categóricas\n","categorical_columns = sample_total_data.select_dtypes(include=['object', 'category']).columns.tolist()\n","\n","# Imprimir los resultados\n","print(f'Número de columnas numéricas: {len(numeric_columns)}')\n","print('Columnas numéricas:', numeric_columns)\n","\n","print(f'Número de columnas categóricas: {len(categorical_columns)}')\n","print('Columnas categóricas:', categorical_columns)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Análisis de valores faltantes\n","sample_total_data.isnull().sum().sort_values(ascending=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sample_total_data.drop([\"class\", \"neo\", \"pha\"], axis = 1, inplace = True)\n","sample_total_data.head(1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","total_data_mv = pd.read_csv('../Project/sampled_dataset.csv')\n","\n","total_data_mv.head(1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Borrado de variables \n","total_data_mv[\"neo_n\"] = pd.factorize(total_data_mv[\"neo\"])[0]\n","total_data_mv[\"pha_n\"] = pd.factorize(total_data_mv[\"pha\"])[0]\n","total_data_mv[\"class_n\"] = pd.factorize(total_data_mv[\"class\"])[0]\n","total_data_mv.drop([\"id\", \"spkid\", \"full_name\",\"pdes\",\"name\",\"prefix\",\"orbit_id\",\"rms\",\"sigma_e\",'sigma_e', 'sigma_a', 'sigma_q', 'sigma_i', 'sigma_om', 'sigma_w', 'sigma_ma', 'sigma_ad', 'sigma_n', 'sigma_tp', 'sigma_per','equinox','epoch','epoch_cal',\"per\",\"moid_ld\", \"epoch_mjd\",\"e\", \"i\", \"om\", \"w\", \"ma\", \"tp\",\"neo_n\",\"pha_n\",\"diameter\",\"diameter_sigma\",\"albedo\",\"class\", \"neo\", \"pha\"], axis = 1, inplace = True)\n","total_data_mv.head(1)"]},{"cell_type":"markdown","metadata":{},"source":["Contabilización de columnas numéricas y categóricas después de eliminar columnas por valores faltantes:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Identificar columnas numéricas\n","numeric_columns = total_data_mv.select_dtypes(include=['float64','int64']).columns.tolist()\n","\n","# Identificar columnas categóricas\n","categorical_columns = total_data_mv.select_dtypes(include=['object', 'category']).columns.tolist()\n","\n","# Imprimir los resultados\n","print(f'Número de columnas numéricas: {len(numeric_columns)}')\n","print('Columnas numéricas:', numeric_columns)\n","\n","print(f'Número de columnas categóricas: {len(categorical_columns)}')\n","print('Columnas categóricas:', categorical_columns)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["total_data_mv.isnull().sum().sort_values(ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["total_data_mv.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Iterar sobre cada columna y reemplazar NaN con la media\n","for column in total_data_mv.columns:\n","    mean_value = total_data_mv[column].mean()\n","    total_data_mv[column].fillna(mean_value, inplace=True)\n","\n","total_data_mv.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["total_data_mv.isnull().sum().sort_values(ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Escalado de valores\n","from sklearn.preprocessing import MinMaxScaler\n","\n","num_variables = ['H', 'a', 'q', 'ad', 'n', 'tp_cal', 'per_y', 'class_n']\n","scaler = MinMaxScaler()\n","scal_features = scaler.fit_transform(total_data_mv[num_variables])\n","df_scal = pd.DataFrame(scal_features, index = total_data_mv.index, columns = num_variables)\n","df_scal[\"moid\"] = total_data_mv[\"moid\"]\n","df_scal.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Dividir el conjunto en train y test\n","from sklearn.model_selection import train_test_split\n","\n","X = df_scal.drop(columns=[\"moid\"])\n","y = df_scal[\"moid\"]\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n","\n","X_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Guardado de datos separados\n","X_train[\"moid\"] = list(y_train)\n","X_test[\"moid\"] = list(y_test)\n","X_train.to_csv(\"clean_train.csv\", index = False)\n","X_test.to_csv(\"clean_test.csv\", index = False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.feature_selection import chi2, SelectKBest\n","from sklearn.model_selection import train_test_split\n","\n","from sklearn.feature_selection import f_classif, SelectKBest\n","\n","selection_model = SelectKBest(f_classif, k = 5)\n","selection_model.fit(X_train, y_train)\n","ix = selection_model.get_support()\n","X_train_sel = pd.DataFrame(selection_model.transform(X_train), columns = X_train.columns.values[ix])\n","X_test_sel = pd.DataFrame(selection_model.transform(X_test), columns = X_test.columns.values[ix])\n","\n","X_train_sel.head()"]},{"cell_type":"markdown","metadata":{},"source":["#### **MODELOS**"]},{"cell_type":"markdown","metadata":{},"source":["6. **Creación de modelos**"]},{"cell_type":"markdown","metadata":{},"source":["Se busca analizar la probabilidad que algunos de los asteriores en orbita con el sistema solar pueda tener un impacto con el planeta tierra, este análisis se le denomina MOID de sus siglas en ingles, \"Minimum Orbit Intersection Distance\" se procederán a desarrollar los modelos con el próposito de encontrar cual de ellos es mas consecuente con la variable objetivo"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# DATA\n","import pandas as pd\n","\n","total_data_mv= pd.read_csv('../Project/total_data_mv.csv')\n","total_data_mv.head(1)"]},{"cell_type":"markdown","metadata":{},"source":["**Arboles de desicion**"]},{"cell_type":"markdown","metadata":{},"source":["Se ha seleccionado por ser fácil de interpretar y útil para relaciones no lineales."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_data = pd.read_csv(\"..\\Project\\clean_test.csv\")\n","train_data = pd.read_csv(\"..\\Project\\clean_train.csv\")\n","\n","train_data.head(3)"]},{"cell_type":"markdown","metadata":{},"source":["Existe un error de codigo con la base de datos original,la imagen generada es demasiado grande para ser procesada y visualizada, por lo que se graficara un muestra, se seleccionara una muestra aleatoria de 10000 filas."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","sampled_data = total_data_mv.sample(n=10000, random_state=42)\n","\n","plt.figure(figsize=(8, 6))\n","pd.plotting.parallel_coordinates(sampled_data, \"moid\", color=(\"red\", \"navy\", \"yellow\"))\n","plt.legend([], [], frameon=False) \n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train = train_data.drop([\"moid\"], axis = 1)\n","y_train = train_data[\"moid\"]\n","X_test = test_data.drop([\"moid\"], axis = 1)\n","y_test = test_data[\"moid\"]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split\n","\n","# Convertir valores continuos a categorías discretas con 3 clases\n","y_train_discrete = pd.cut(y_train, bins=3, labels=[\"bajo\", \"medio\", \"alto\"])\n","y_test_discrete = pd.cut(y_test, bins=3, labels=[\"bajo\", \"medio\", \"alto\"])\n","\n","# Crear y entrenar el modelo\n","model = DecisionTreeClassifier(random_state=42)\n","model.fit(X_train, y_train_discrete)\n","\n","# Predecir y evaluar\n","y_pred = model.predict(X_test)\n","print(\"Predicciones:\", y_pred)\n"]},{"cell_type":"markdown","metadata":{},"source":["Al utilizar el modelo de defecto \"clasificador\", arrojaba error ya que los valores eran continuos, se ha optimizado el modelo con una variable discreta que son especificas de este tipo de datos."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn import tree\n","\n","fig = plt.figure(figsize=(15,15))\n","\n","tree.plot_tree(model, feature_names = list(X_train.columns), class_names = [\"0\", \"1\", \"2\"], filled = True)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = model.predict(X_test)\n","y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Optimización del modelo \n","\n","import pandas as pd\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import accuracy_score\n","import warnings\n","\n","# Función para suprimir advertencias\n","def warn(*args, **kwargs):\n","    pass\n","\n","warnings.warn = warn\n","\n","X = total_data_mv.drop(columns=[\"moid\"])\n","y = total_data_mv[\"moid\"]\n","\n","# Dividir los datos en conjuntos de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Convertir valores continuos de MOID a categorías discretas con 3 clases\n","y_train_discrete = pd.cut(y_train, bins=3, labels=[\"bajo\", \"medio\", \"alto\"])\n","y_test_discrete = pd.cut(y_test, bins=3, labels=[\"bajo\", \"medio\", \"alto\"])\n","\n","# Crear el modelo de DecisionTreeClassifier\n","model = DecisionTreeClassifier(random_state=42)\n","\n","# Definir el grid de hiperparámetros a buscar\n","param_grid = {\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 10, 20],\n","    'min_samples_leaf': [1, 5, 10]\n","}\n","\n","# Crear el GridSearchCV con validación cruzada de 5 pliegues\n","grid = GridSearchCV(model, param_grid, cv=5)\n","grid.fit(X_train, y_train_discrete)\n","\n","# Mostrar los mejores hiperparámetros encontrados\n","print(f\"Mejores hiperparámetros: {grid.best_params_}\")\n","\n","# Evaluar el modelo con los mejores hiperparámetros en el conjunto de prueba\n","y_pred = grid.predict(X_test)\n","accuracy = accuracy_score(y_test_discrete, y_pred)\n","print(\"Exactitud:\", accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.tree import DecisionTreeRegressor\n","\n","# Crear un modelo de regresión de árbol de decisión\n","model = DecisionTreeRegressor(max_depth=None, min_samples_leaf=1, min_samples_split=2, random_state=42)\n","\n","model.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.tree import DecisionTreeRegressor\n","from sklearn.metrics import mean_squared_error\n","\n","# Crear un modelo de regresión de árbol de decisión\n","model = DecisionTreeRegressor(max_depth=None, min_samples_leaf=1, min_samples_split=2, random_state=42)\n","\n","# Ajustar el modelo a los datos de entrenamiento\n","model.fit(X_train, y_train)\n","\n","# Hacer predicciones con los datos de prueba\n","y_pred = model.predict(X_test)\n","\n","# Evaluar el modelo (por ejemplo, calcular el error cuadrático medio)\n","mse = mean_squared_error(y_test, y_pred)\n","print(f\"Error cuadrático medio: {mse}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","# Función para calcular \"accuracy\" para valores continuos\n","def accuracy_continuous(y_true, y_pred, tolerance=0.5):\n","    correct = np.abs(y_true - y_pred) <= tolerance\n","    return np.mean(correct)\n","\n","# Ejemplo de uso\n","y_true = np.array([1.5, 2.0, 3.7, 4.1])\n","y_pred = np.array([1.7, 1.8, 3.6, 4.3])\n","\n","acc = accuracy_continuous(y_true, y_pred, tolerance=0.5)\n","print(f\"Accuracy score: {acc}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["**Regresión lineal**"]},{"cell_type":"markdown","metadata":{},"source":["Este modelo establece una relación matemática entre variables independientes y una variable dependiente \"moid\", permitiendo predecir valores continuos de MOID en función de las características que se seleccionen."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","\n","model = LinearRegression()\n","model.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f\"Intercep (a): {model.intercept_}\")\n","print(f\"Coefficients (b1, b2): {model.coef_}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = model.predict(X_test)\n","y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import mean_squared_error, r2_score\n","\n","print(f\"MSE: {mean_squared_error(y_test, y_pred)}\")\n","print(f\"R2 Score: {r2_score(y_test, y_pred)}\")"]},{"cell_type":"markdown","metadata":{},"source":["Se descarta por que para mejorar el modelo de predicción del MOID, sería deseable reducir el MSE y aumentar el R^2 Score hacia valores más cercanos a 1. Esto se podría lograr ajustando el modelo, considerando más características relevantes y/o aumentando la cantidad de datos de entrenamiento, también utilizando métodos de modelado más avanzados que puedan capturar mejor las relaciones en los datos del MOID."]},{"cell_type":"markdown","metadata":{},"source":["**K-Nearest Neighbors**"]},{"cell_type":"markdown","metadata":{},"source":["Se selecciona este modelo porque trabajaba basándose en características específicas, proporcionando una herramienta crítica para la evaluación de riesgos de colisión."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","import pandas as pd\n","\n","# X contiene las características relevantes y y contiene los valores de MOID\n","X = total_data_mv[['H', 'a', 'q', 'ad', 'n', 'tp_cal', 'per_y', 'class_n']]\n","\n","# Dividir los datos en conjuntos de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Escalar las características (es opcional pero recomendado para k-NN)\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Crear un modelo de k-Nearest Neighbors Regressor\n","k = 5  # Número de vecinos\n","model = KNeighborsRegressor(n_neighbors=k)\n","\n","# Ajustar el modelo a los datos de entrenamiento\n","model.fit(X_train_scaled, y_train)\n","\n","# Hacer predicciones con los datos de prueba\n","y_pred = model.predict(X_test_scaled)\n","\n","# Calcular métricas de evaluación\n","mse = mean_squared_error(y_test, y_pred)\n","r2 = r2_score(y_test, y_pred)\n","\n","print(f\"Mean Squared Error (MSE): {mse}\")\n","print(f\"R^2 Score: {r2}\")"]},{"cell_type":"markdown","metadata":{},"source":["**Random Forest regressor**"]},{"cell_type":"markdown","metadata":{},"source":["Se selecciona por ser efectivo para capturar interacciones complejas entre las características orbitales y el MOID, proporcionando predicciones concretas y generalizables. Además es ideal para datos grandes y variados sin sobreajuste."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import pandas as pd\n","\n","# X contiene las características relevantes y y contiene los valores de MOID\n","X = total_data_mv[['H', 'a', 'q', 'ad', 'n', 'tp_cal', 'per_y', 'class_n']]  \n","y = total_data_mv['moid']\n","\n","# Dividir los datos en conjuntos de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Escalar las características (es opcional pero recomendado para Random Forest)\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Crear un modelo de Random Forest Regressor\n","model = RandomForestRegressor(n_estimators=100, random_state=42)\n","\n","# Ajustar el modelo a los datos de entrenamiento\n","model.fit(X_train_scaled, y_train)\n","\n","# Hacer predicciones con los datos de prueba\n","y_pred = model.predict(X_test_scaled)\n","\n","# Calcular métricas de evaluación\n","mse = mean_squared_error(y_test, y_pred)\n","r2 = r2_score(y_test, y_pred)\n","\n","print(f\"Mean Squared Error (MSE): {mse}\")\n","print(f\"R^2 Score: {r2}\")"]},{"cell_type":"markdown","metadata":{},"source":["**Gradient boosting regressor**"]},{"cell_type":"markdown","metadata":{},"source":["Es otro método de aprendizaje conjunto que construye una serie de modelos de forma secuencial, donde cada nuevo modelo corrige los errores del modelo anterior. Utiliza árboles de decisión como estimadores base y optimiza una función de pérdida diferenciable para mejorar las predicciones."]},{"cell_type":"markdown","metadata":{},"source":["Se selecciona por su capacidad probada para mejorar predicciones en problemas de regresión mediante la construcción secuencial de árboles de decisión, corrigiendo errores de modelos anteriores y manejando relaciones no lineales de manera efectiva. Este captura la complejidad de las relaciones entre las características orbitales y el MOID, ofreciendo una alta precisión y evitando el sobreajuste mediante la regularización incorporada (esta última se refiere a técnicas integradas en los modelos de aprendizaje automático que ayudan a prevenir el sobreajuste y mejorar la generalización del modelo)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import pandas as pd\n","\n","# X contiene las características relevantes y y contiene los valores de MOID\n","X = total_data_mv[['H', 'a', 'q', 'ad', 'n', 'tp_cal', 'per_y', 'class_n']] \n","y = total_data_mv['moid']\n","\n","# Dividir los datos en conjuntos de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Escalar las características, es opcional pero recomendado para Gradient Boosting\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Crear un modelo de Gradient Boosting Regressor\n","model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n","\n","# Ajustar el modelo a los datos de entrenamiento\n","model.fit(X_train_scaled, y_train)\n","\n","# Hacer predicciones con los datos de prueba\n","y_pred = model.predict(X_test_scaled)\n","\n","# Calcular métricas de evaluación\n","mse = mean_squared_error(y_test, y_pred)\n","r2 = r2_score(y_test, y_pred)\n","\n","print(f\"Mean Squared Error (MSE): {mse}\")\n","print(f\"R^2 Score: {r2}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Visualizar los resultados con gráficos\n","# Plotting the true values vs predicted values\n","plt.figure(figsize=(10, 6))\n","plt.scatter(y_test, y_pred, alpha=0.5)\n","plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')  # Perfect prediction line\n","plt.xlabel('True Values')\n","plt.ylabel('Predicted Values')\n","plt.title('True Values vs Predicted Values')\n","plt.show()\n","\n","# Plotting the residuals\n","residuals = y_test - y_pred\n","plt.figure(figsize=(10, 6))\n","sns.histplot(residuals, kde=True)\n","plt.xlabel('Residuals')\n","plt.ylabel('Frequency')\n","plt.title('Residuals Distribution')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Los resultados obtenidos nos demuestrasn que el modelo a sido evaluado y entrenado con éxito.\n","\n","Los resultados obtenidos se pueden valorar de la siguiente forma:\n","\n","Mean Squared Error (MSE): 0.0047308846179628375\n","\n","El MSE es una métrica que mide la diferencia entre los valores predichos y los valores reales. Un valor bajo de MSE indica que el modelo es capaz de hacer predicciones precisas. En nuestro caso, el MSE es muy bajo, lo que sugiere que el modelo es capaz de hacer predicciones muy precisas.\n","\n","R^2 Score: 0.9985490383742801\n","\n","El R^2 Score es una métrica que mide la variabilidad en los datos que es explicada por el modelo. Un valor cercano a 1 indica que el modelo explica la mayoría de la variabilidad en los datos. En nuestro caso, el R^2 Score es muy alto, lo que sugiere que el modelo es capaz de explicar la mayoría de la variabilidad en los datos de MOID.\n","\n","**Conclusión**:\n","\n","En general, los resultados sugieren que el modelo de Random Forest Regressor es muy efectivo para predecir los valores de MOID a partir de las características orbitales. La baja MSE y el alto R^2 Score indican que el modelo es capaz de hacer predicciones precisas y generalizables.\n","\n","Ventajas del modelo\n","\n","El modelo de Random Forest Regressor es capaz de capturar interacciones complejas entre las características orbitales y el MOID. El modelo es robusto y no se sobreajusta, lo que lo hace ideal para datos grandes y variados."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#vsfa"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
